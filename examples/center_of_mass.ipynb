{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Center of Mass calculation\n",
    "\n",
    "Prerequisites: \n",
    "\n",
    " * a python3.6 virtualenv with all requirements installed\n",
    "  * ``pip install -e .`` in your LiberTEM source dir\n",
    "  * ``pip install hyperspy hyperspy_gui_ipywidgets`` for additional dependencies\n",
    " * a HDF5 dataset in float or double format, with shape ``(256, 256, 128, 128)`` (can use different datasets if you replace the hardcoded values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib nbagg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We disable threading in OpenBLAS because it would interfere with the dask multiprocessing and because OpenBLAS likes to call ``sched_yield`` for no discernable reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import our dependencies. There may be some warnings about ``hyperspy_gui_traitui`` and so on which can be safely ignored (you do need ``hyperspy_gui_ipywidgets`` though):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/clausen/.virtualenvs/libertem2/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "WARNING:hyperspy.api:The traitsui GUI elements are not available, probably because the hyperspy_gui_traitui package is not installed.\n"
     ]
    }
   ],
   "source": [
    "from libertem.dataset.hdf5 import H5DataSet\n",
    "from libertem.executor.dask import DaskJobExecutor\n",
    "from libertem.job.masks import ApplyMasksJob\n",
    "from libertem.utils import _make_circular_mask\n",
    "from scipy.ndimage import measurements\n",
    "from dask import distributed as dd\n",
    "import numpy as np\n",
    "import hyperspy.api as hs\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we prepare for the actual computation. Center of Mass for a 2D image means multiplying each pixel's intensity with it's position and dividing by the sum of all pixel intensities. We do this separately for ``x`` and ``y`` axis by creating a gradient ``0..127`` for each axis, and a \"all ones\" mask for the sum of all pixels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see also: https://github.com/scipy/scipy/blob/v0.16.1/scipy/ndimage/measurements.py#L1232\n",
    "x_gradient = np.tile(np.ogrid[slice(0, 128)].astype(np.float32), 128).reshape(128, 128)\n",
    "\n",
    "masks=[\n",
    "    # summation of all pixels:\n",
    "    np.ones(shape=(128, 128)),\n",
    "    \n",
    "    # gradient from left to right\n",
    "    x_gradient,\n",
    "    \n",
    "    # transpose() to make gradient from top to bottom:\n",
    "    x_gradient.transpose(),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we set up the parameters for the job. If you want to run this notebook, you may need to adjust the ``dataset_path`` variable and ``ds_path`` parameter here. This example uses a local HDF5 file as input dataset, but you can use the HDFS DataSet implementation if you want to use your cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stackheight = 8\n",
    "dataset_path = \"/home/clausen/Data/EMPAD/scan_11_x256_y256.emd\"\n",
    "ds = H5DataSet(\n",
    "    path=dataset_path,\n",
    "    ds_path=\"experimental/science_data/data\",\n",
    "    stackheight=stackheight\n",
    ")\n",
    "job = ApplyMasksJob(dataset=ds, masks=masks)\n",
    "cluster = dd.LocalCluster(threads_per_worker=1)\n",
    "client = dd.Client(cluster)\n",
    "# executor = DaskJobExecutor(client=client, is_local=True)\n",
    "executor = DaskJobExecutor.make_local()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For visualization, we create a HyperSpy signal. For each of our masks, it holds the result values for all scan positions. You can use the slider to switch between masks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_result = hs.signals.Signal2D(np.zeros(shape=(job.maskcount, 256, 256)))\n",
    "full_result.axes_manager[0].name = \"masks\"\n",
    "full_result.axes_manager[1].name = \"x\"\n",
    "full_result.axes_manager[2].name = \"y\"\n",
    "full_result.plot(navigator=\"slider\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we kick off the computation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    for result in executor.run_job(job):\n",
    "        for tile in result:\n",
    "            tile.copy_to_result(full_result.data)\n",
    "    full_result.events.data_changed.trigger(full_result)\n",
    "%time run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create another signal that contains the ``(x, y)`` pairs as signal for each scan position:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_centers = np.divide(full_result.inav[1].data, full_result.inav[0].data)\n",
    "y_centers = np.divide(full_result.inav[2].data, full_result.inav[0].data)\n",
    "centers = hs.signals.Signal1D(np.dstack((x_centers, y_centers)))\n",
    "centers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now that we have our results, let's see how we compare to the ``scipy`` implementation. Let's use HyperSpy to load the dataset lazily (``optimize=False`` because of the lazy signal):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = hs.load(dataset_path, lazy=True).as_signal2D(image_axes=(0, 1), optimize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at one frame, plot it and see how the result compares to ours:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_coords = (64, 64)\n",
    "frame = raw_data.inav[frame_coords]\n",
    "frame.plot(navigator=None)\n",
    "frame_data = frame.data.compute()\n",
    "center_y, center_x = measurements.center_of_mass(frame_data)\n",
    "# marker = hs.plot.markers.point(x=center_x, y=center_y, color='red')\n",
    "# frame.add_marker(marker) # -> crashes for some reason\n",
    "print(\"scipy center: x=%.6f, y=%.6f\" % (center_x, center_y))\n",
    "print(\"our center:   x=%.6f, y=%.6f\" % (centers.inav[frame_coords].isig[0].data[0],\n",
    "                                      centers.inav[frame_coords].isig[1].data[0]))\n",
    "print(\"difference from scipy: x=%.6f, y=%.6f\" % (\n",
    "    (center_x - centers.inav[frame_coords].isig[0].data[0]),\n",
    "    (center_y - centers.inav[frame_coords].isig[1].data[0])\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
